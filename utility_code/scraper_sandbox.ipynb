{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://en.wikipedia.org/wiki/Lionel_Messi\"\n",
    "# url = \"https://en.wikipedia.org/wiki/Cristiano_Ronaldo\"\n",
    "# url = \"https://fbref.com/en/players/21a66f6a/Harry-Kane\"\n",
    "# url = \"https://en.wikipedia.org/wiki/Folarin_Balogun\"\n",
    "url = 'https://duckduckgo.com/?q=cristiano+ronaldo'\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_club_urls(soup):\n",
    "    table = soup.find('tbody')\n",
    "    links = table.find_all('a')\n",
    "    club_urls = [\"https://fbref.com\" + link['href'] for link in links if 'squads' in link['href']]\n",
    "    return club_urls\n",
    "\n",
    "\n",
    "def get_club_urls():\n",
    "    url = 'https://fbref.com/en/comps/Big5/Big-5-European-Leagues-Stats'\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "    club_urls = extract_club_urls(soup)\n",
    "    return club_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single player \n",
    "def extract_player_urls(soup):\n",
    "    global counter\n",
    "    global player_url_dict \n",
    "\n",
    "\n",
    "    table = soup.find('tbody')\n",
    "    links = table.find_all('a')\n",
    "    player_urls = [\"https://fbref.com\" + link['href']\\\n",
    "        for link in links if\\\n",
    "        'players' in link['href'] and\\\n",
    "        'matchlogs' not in link['href']]\n",
    "    \n",
    "    for url in player_urls:\n",
    "        counter += 1\n",
    "        player_url_dict[counter] = url\n",
    "\n",
    "\n",
    "\n",
    "def get_player_urls(club_url): #output should be a url\n",
    "    time.sleep(2*random.random()) #use throttle as class attribute\n",
    "    soup = BeautifulSoup(requests.get(club_url).text, 'html.parser')\n",
    "    extract_player_urls(soup)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor: \n",
    "    counter = 0\n",
    "    player_url_dict = {}\n",
    "    executor.map(get_player_urls, club_urls[:2])###remove slicing\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractScraper(ABC):\n",
    "    def __init__(self) -> None:\n",
    "        self.urls = []\n",
    "        self.response = None\n",
    "        self.soup = None\n",
    "        self.result = None\n",
    "        self.max_workers = 3\n",
    "\n",
    "    @abstractmethod\n",
    "    def start_crawl_threads(self, urls):        \n",
    "        pass\n",
    "\n",
    "    @abstractmethod    \n",
    "    def get_content(self, url):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod        \n",
    "    def extract_data(self, soup):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod    \n",
    "    def store_result(self, result):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod    \n",
    "    def show_result(self, result):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod    \n",
    "    def save_result(self,result):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scraper = Scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(h):\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_content() missing 1 required positional argument: 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132592/1233571038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_scraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_content() missing 1 required positional argument: 'url'"
     ]
    }
   ],
   "source": [
    "test_scraper.get_content() = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "903c6381022ce11ae579cb5a90d8a6f3bd5bf0e7eda2a8c44ca8e21e5da2e68b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
